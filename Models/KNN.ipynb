{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import random\n",
    "\n",
    "num_of_centroids=4096\n",
    "num_train_samples=200\n",
    "num_test_samples=40\n",
    "K = 11\n",
    "all_image_idx=random.sample(range(0,1000),num_train_samples+num_test_samples)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "from skimage.filters import unsharp_mask\n",
    "\n",
    "def remove_noise (image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    X = cv2.bilateralFilter(gray, 15, sigmaColor=10, sigmaSpace=10)\n",
    "    median = cv2.medianBlur(X, 5)\n",
    "    result_2 = unsharp_mask(median, radius=10, amount=4)*255\n",
    "    result_2 = np.uint8(result_2)\n",
    "    sharpen = cv2.Canny(result_2, 100,250)\n",
    "\n",
    "    # Create a kernel for morphological operations\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    # # Close the edges using morphological closing\n",
    "    closed_edges = cv2.morphologyEx(sharpen, cv2.MORPH_CLOSE, kernel)\n",
    "    return closed_edges\n",
    "\n",
    "def show_images(images, titles=None):\n",
    "    n_ims = len(images)\n",
    "    if titles is None:\n",
    "        titles = ['(%d)' % i for i in range(1, n_ims + 1)]\n",
    "    fig = plt.figure()\n",
    "    n = 1\n",
    "    for image, title in zip(images, titles):\n",
    "        a = fig.add_subplot(1, n_ims, n)\n",
    "        if image.ndim == 2:\n",
    "            plt.gray()\n",
    "        plt.imshow(image)\n",
    "        a.set_title(title)\n",
    "        n += 1\n",
    "    fig.set_size_inches(np.array(fig.get_size_inches()) * n_ims)\n",
    "    plt.show()"
   ],
   "id": "50fe890f0fce7be2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "all_des=np.empty((1,128))\n",
    "\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "num_of_desc=[]\n",
    "\n",
    "for i in range (num_train_samples):\n",
    "    image = cv2.imread(\"../../fonts-dataset/IBM Plex Sans Arabic/\"+str(all_image_idx[i])+\".jpeg\")\n",
    "    removed_noise = remove_noise(image)\n",
    "    kp , descriptors= sift.detectAndCompute(removed_noise,None)\n",
    "    if descriptors is not None:\n",
    "        all_des=np.vstack((all_des,descriptors))\n",
    "    print(\"processing type 1 image\"+str(i))\n",
    "\n",
    "num_of_desc+=[all_des.shape[0]]\n",
    "print(\"FINISHED READING FIRST SET OF IMAGES\")\n",
    "\n",
    "for i in range (num_train_samples):\n",
    "    image = cv2.imread(\"../../fonts-dataset/Lemonada/\"+str(all_image_idx[i])+\".jpeg\")\n",
    "    removed_noise = remove_noise(image)\n",
    "    kp , descriptors= sift.detectAndCompute(removed_noise,None)\n",
    "    if descriptors is not None:\n",
    "        all_des=np.vstack((all_des,descriptors))\n",
    "    print(\"processing type 2 image\"+str(i))\n",
    "\n",
    "num_of_desc+=[all_des.shape[0]]\n",
    "print(\"FINISHED READING SECOND SET OF IMAGES\")\n",
    "\n",
    "for i in range (num_train_samples):\n",
    "    image = cv2.imread(\"../../fonts-dataset/Marhey/\"+str(all_image_idx[i])+\".jpeg\")\n",
    "    removed_noise = remove_noise(image)\n",
    "    kp , descriptors= sift.detectAndCompute(removed_noise,None)\n",
    "    if descriptors is not None:\n",
    "        all_des=np.vstack((all_des,descriptors))\n",
    "    print(\"processing type 3 image\"+str(i))\n",
    "\n",
    "num_of_desc+=[all_des.shape[0]]\n",
    "print(\"FINISHED READING THIRD SET OF IMAGES\")\n",
    "\n",
    "\n",
    "for i in range (num_train_samples):\n",
    "    image = cv2.imread(\"../../fonts-dataset/Scheherazade New/\"+str(all_image_idx[i])+\".jpeg\")\n",
    "    removed_noise = remove_noise(image)\n",
    "    kp , descriptors= sift.detectAndCompute(removed_noise,None)\n",
    "    if descriptors is not None:\n",
    "        all_des=np.vstack((all_des,descriptors))\n",
    "    print(\"processing type 4 image\"+str(i))\n",
    "\n",
    "num_of_desc+=[all_des.shape[0]]\n",
    "print(\"FINISHED READING FOURTH SET OF IMAGES\")\n",
    "\n",
    "desc_labels=np.zeros(all_des.shape[0])\n",
    "desc_labels[num_of_desc[0]:num_of_desc[1]]=1\n",
    "desc_labels[num_of_desc[1]:num_of_desc[2]]=2\n",
    "desc_labels[num_of_desc[2]:num_of_desc[3]]=3"
   ],
   "id": "7fe0334ecaff56a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# different options for kmeans\n",
    "# - mini batches\n",
    "# - limiting the number of descriptors\n",
    "kmeans=MiniBatchKMeans(n_clusters=num_of_centroids,batch_size=num_of_centroids*1024,max_iter=20).fit(X=all_des)"
   ],
   "id": "1022a8b7fd17a465",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# for each centroid, calculate how it is near to each label\n",
    "centroids_labels=np.zeros((num_of_centroids,4))\n",
    "for i in range(num_of_centroids):\n",
    "    centroids_labels[i][0]=(np.sum(desc_labels[kmeans.labels_==i]==0))  ## kmeans.labels_ -> array to map each descriptor to a centroid\n",
    "    centroids_labels[i][1]=(np.sum(desc_labels[kmeans.labels_==i]==1))\n",
    "    centroids_labels[i][2]=(np.sum(desc_labels[kmeans.labels_==i]==2))\n",
    "    centroids_labels[i][3]=(np.sum(desc_labels[kmeans.labels_==i]==3))\n",
    "    centroids_labels[i]/=np.sum(centroids_labels[i])\n",
    "print(centroids_labels[0][0], centroids_labels[0][1], centroids_labels[0][2], centroids_labels[0][3])"
   ],
   "id": "a22dab9adaae26a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def predict(path,centroids,centroids_labels):\n",
    "    image=cv2.imread(path)\n",
    "    removed_noise = remove_noise(image)\n",
    "    _ , descriptors= sift.detectAndCompute(removed_noise,None)\n",
    "\n",
    "    predections=[0.0,0.0,0.0,0.0]\n",
    "    if descriptors is not None:\n",
    "        for des in descriptors:\n",
    "            idx=kmeans.predict([des])\n",
    "            dist=np.linalg.norm(des-centroids[idx])\n",
    "            if dist == 0:\n",
    "                dist = 0.0000001\n",
    "            predections+=(centroids_labels[idx]/dist)\n",
    "        return np.argmax(predections)\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "num_right0=0\n",
    "num_right1=0\n",
    "num_right2=0\n",
    "num_right3=0\n",
    "\n",
    "predictions=[]\n",
    "\n",
    "for i in range (num_test_samples):\n",
    "    rand_idx=str(all_image_idx[num_train_samples+i])\n",
    "    path=\"../../fonts-dataset/IBM Plex Sans Arabic/\"+rand_idx+\".jpeg\"\n",
    "\n",
    "    predicted=predict(path,kmeans.cluster_centers_,centroids_labels)\n",
    "    print(\"image\",(rand_idx), \"type0: \",predicted)\n",
    "    num_right0+=predicted==0\n",
    "    predictions.append(predicted)\n",
    "\n",
    "for i in range (num_test_samples):\n",
    "    rand_idx=str(all_image_idx[num_train_samples+i])\n",
    "    path=\"../../fonts-dataset/Lemonada/\"+rand_idx+\".jpeg\"\n",
    "\n",
    "    predicted=predict(path,kmeans.cluster_centers_,centroids_labels)\n",
    "    print(\"image\",(rand_idx), \"type1: \",predicted)\n",
    "    num_right1+=predicted==1\n",
    "    predictions.append(predicted)\n",
    "\n",
    "for i in range (num_test_samples):\n",
    "    rand_idx=str(all_image_idx[num_train_samples+i])\n",
    "\n",
    "    path=\"../../fonts-dataset/Marhey/\"+rand_idx+\".jpeg\"\n",
    "\n",
    "    predicted=predict(path,kmeans.cluster_centers_,centroids_labels)\n",
    "    print(\"image\",(rand_idx), \"type2: \",predicted)\n",
    "    num_right2+=predicted==2\n",
    "    predictions.append(predicted)\n",
    "\n",
    "for i in range (num_test_samples):\n",
    "    rand_idx=str(all_image_idx[num_train_samples+i])\n",
    "\n",
    "    path=\"../../fonts-dataset/Scheherazade New/\"+rand_idx+\".jpeg\"\n",
    "\n",
    "    predicted=predict(path,kmeans.cluster_centers_,centroids_labels)\n",
    "    print(\"image\",(rand_idx), \"type3: \",predicted)\n",
    "    num_right3+=predicted==3\n",
    "    predictions.append(predicted)"
   ],
   "id": "4244e1a2a28cb4b2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(num_right0)\n",
    "print(num_right1)\n",
    "print(num_right2)\n",
    "print(num_right3)\n",
    "\n",
    "print((num_right0+num_right1+num_right2+num_right3)/(4*num_test_samples))"
   ],
   "id": "ab40686fa01119e7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def predict_knn(path,centroids_labels,knn):\n",
    "    image=cv2.imread(path)\n",
    "    removed_noise = remove_noise(image)\n",
    "    _ , descriptors= sift.detectAndCompute(removed_noise,None)\n",
    "\n",
    "    predections=[0.0,0.0,0.0,0.0]\n",
    "    if descriptors is not None:\n",
    "        for des in descriptors:\n",
    "            neigh=knn.kneighbors([des])\n",
    "            for i in range(K):\n",
    "                predections+=(centroids_labels[neigh[1][0][i]]/neigh[0][0][i])\n",
    "        print(predections)\n",
    "        return np.argmax(predections)\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "knn = NearestNeighbors(n_neighbors=K)\n",
    "classes=np.arange(0, num_of_centroids, 1, dtype=int)\n",
    "knn.fit(kmeans.cluster_centers_,classes)\n",
    "\n",
    "predictions=[]\n",
    "\n",
    "for i in range (num_test_samples):\n",
    "    rand_idx=str(all_image_idx[num_train_samples+i])\n",
    "    path=\"../../fonts-dataset/IBM Plex Sans Arabic/\"+rand_idx+\".jpeg\"\n",
    "\n",
    "    predicted=predict_knn(path,centroids_labels,knn)\n",
    "    print(\"image\",(rand_idx), \"type0: \",predicted)\n",
    "    num_right0+=predicted==0\n",
    "    predictions+=predicted\n",
    "\n",
    "for i in range (num_test_samples):\n",
    "    rand_idx=str(all_image_idx[num_train_samples+i])\n",
    "    path=\"../../fonts-dataset/Lemonada/\"+rand_idx+\".jpeg\"\n",
    "\n",
    "    predicted=predict_knn(path,centroids_labels,knn)\n",
    "    print(\"image\",(rand_idx), \"type1: \",predicted)\n",
    "    num_right1+=predicted==1\n",
    "    predictions+=predicted\n",
    "\n",
    "for i in range (num_test_samples):\n",
    "    rand_idx=str(all_image_idx[num_train_samples+i])\n",
    "\n",
    "    path=\"../../fonts-dataset/Marhey/\"+rand_idx+\".jpeg\"\n",
    "\n",
    "    predicted=predict_knn(path,centroids_labels,knn)\n",
    "    print(\"image\",(rand_idx), \"type2: \",predicted)\n",
    "    num_right2+=predicted==2\n",
    "    predictions+=predicted\n",
    "\n",
    "for i in range (num_test_samples):\n",
    "    rand_idx=str(all_image_idx[num_train_samples+i])\n",
    "\n",
    "    path=\"../../fonts-dataset/Scheherazade New/\"+rand_idx+\".jpeg\"\n",
    "\n",
    "    predicted=predict_knn(path,centroids_labels,knn)\n",
    "    print(\"image\",(rand_idx), \"type3: \",predicted)\n",
    "    num_right3+=predicted==3\n",
    "    predictions+=predicted"
   ],
   "id": "370c3700ed8f1967",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(num_right0)\n",
    "print(num_right1)\n",
    "print(num_right2)\n",
    "print(num_right3)\n",
    "\n",
    "print((num_right0+num_right1+num_right2+num_right3)/(4*num_test_samples))"
   ],
   "id": "78fde68efdcf4bbe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# SVM on ther original des\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "all_des=[]\n",
    "labels=[]\n",
    "sift = cv2.SIFT_create(500)\n",
    "\n",
    "for i in range (10):\n",
    "    image = cv2.imread(\"../../fonts-dataset/Lemonada/\"+str(i)+\".jpeg\")\n",
    "    removed_noise = remove_noise(image)\n",
    "    kp , descriptors= sift.detectAndCompute(removed_noise,None)\n",
    "    \n",
    "    if descriptors is not None:\n",
    "        for des in descriptors:\n",
    "            all_des.append(des)\n",
    "        # append number of labels to the labels array equal to the number of descriptors\n",
    "        for j in range (descriptors.shape[0]):\n",
    "            labels=np.append(labels,0)        \n",
    "    \n",
    "\n",
    "\n",
    "    image2 = cv2.imread(\"../../fonts-dataset/Marhey/\"+str(i)+\".jpeg\")\n",
    "    removed_noise2 = remove_noise(image2)\n",
    "    kp , descriptors= sift.detectAndCompute(removed_noise2,None)\n",
    "\n",
    "    if descriptors is not None:\n",
    "        for des in descriptors:\n",
    "            all_des.append(des)  \n",
    "        # append number of labels to the labels array equal to the number of descriptors\n",
    "        for j in range (descriptors.shape[0]):\n",
    "            labels=np.append(labels,1)\n",
    "\n",
    "    image3 = cv2.imread(\"../../fonts-dataset/IBM Plex Sans Arabic/\"+str(i)+\".jpeg\")\n",
    "    removed_noise3 = remove_noise(image3)\n",
    "    kp , descriptors= sift.detectAndCompute(removed_noise3,None)\n",
    "\n",
    "    if descriptors is not None:\n",
    "        for des in descriptors:\n",
    "            all_des.append(des)\n",
    "        # append number of labels to the labels array equal to the number of descriptors\n",
    "        for j in range (descriptors.shape[0]):\n",
    "            labels=np.append(labels,2)\n",
    "\n",
    "    image4 = cv2.imread(\"../../fonts-dataset/Scheherazade New/\"+str(i)+\".jpeg\")\n",
    "    removed_noise4 = remove_noise(image4)\n",
    "    kp , descriptors= sift.detectAndCompute(removed_noise4,None)\n",
    "\n",
    "    if descriptors is not None:\n",
    "        for des in descriptors:\n",
    "            all_des.append(des)\n",
    "        # append number of labels to the labels array equal to the number of descriptors\n",
    "        for j in range (descriptors.shape[0]):\n",
    "            labels=np.append(labels,3)\n",
    "    \n",
    "    print(i)\n",
    "\n",
    "all_des = np.array(all_des)\n",
    "print(all_des.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_des, labels, test_size=0.2, random_state=42)\n",
    "svm = SVC(kernel='poly', C=0.1, random_state=0, coef0=1, degree=4, gamma=10.0,class_weight= None)\n",
    "print(\"fares1\")\n",
    "svm.fit(X_train, y_train)\n",
    "print(\"fares1\")\n",
    "y_pred = svm.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)"
   ],
   "id": "f34a8e5b500d02a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Fixing individual predictions\n",
    "def remove_noise22 (image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    X = cv2.bilateralFilter(gray, 15, sigmaColor=10, sigmaSpace=10)\n",
    "    median = cv2.medianBlur(X, 5)\n",
    "    result_2 = unsharp_mask(median, radius=10, amount=4)*255\n",
    "    result_2 = np.uint8(result_2)\n",
    "    sharpen = cv2.Canny(result_2, 100,250)\n",
    "    \n",
    "    # Create a kernel for morphological operations\n",
    "    # kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    # \n",
    "    # # Close the edges using morphological closing\n",
    "    # closed_edges = cv2.morphologyEx(sharpen, cv2.MORPH_CLOSE, kernel)\n",
    "    return sharpen\n",
    "\n",
    "def predict22(path,centroids,centroids_labels):\n",
    "    image=cv2.imread(path)\n",
    "    removed_noise = remove_noise22(image)\n",
    "    _ , descriptors= sift.detectAndCompute(removed_noise,None)\n",
    "\n",
    "    predections=[0.0,0.0,0.0,0.0]\n",
    "    if descriptors is not None:\n",
    "        for des in descriptors:\n",
    "            idx=kmeans.predict([des])\n",
    "            dist=np.linalg.norm(des-centroids[idx])\n",
    "            if dist == 0:\n",
    "                dist = 0.0000001\n",
    "            predections+=(centroids_labels[idx]/dist)\n",
    "        print(predections)\n",
    "        return np.argmax(predections)\n",
    "    else:\n",
    "        return -1\n",
    "path=\"../../fonts-dataset/Scheherazade New/840.jpeg\"\n",
    "\n",
    "prediction=predict22(path,kmeans.cluster_centers_,centroids_labels)\n",
    "print(\"image\",(599), \"type3: \",prediction)\n"
   ],
   "id": "c243605187451009",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(\"image\",(599), \"type3: \",prediction)",
   "id": "8685ecc841c8997",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "image = cv2.imread(\"../../fonts-dataset/Scheherazade New/599.jpeg\")\n",
    "removed_noise = remove_noise22(image)\n",
    "# save the image\n",
    "cv2.imwrite(\"1.jpeg\", removed_noise)\n",
    "\n",
    "grayy = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "sharpen = cv2.Canny(grayy, 100,250)\n",
    "cv2.imwrite(\"2.jpeg\", sharpen)\n",
    "\n",
    "result_2 = unsharp_mask(grayy, radius=10, amount=4)*255\n",
    "result_2 = np.uint8(result_2)\n",
    "#X = cv2.bilateralFilter(result_2, 15, sigmaColor=10, sigmaSpace=10)\n",
    "\n",
    "# kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "# \n",
    "# # Close the edges using morphological closing\n",
    "# closed_edges = cv2.morphologyEx(grayy, cv2.MORPH_DILATE, kernel)\n",
    "\n",
    "# median = cv2.medianBlur(X, 5)\n",
    "cv2.imwrite(\"3.jpeg\", result_2)"
   ],
   "id": "8adbaa4b73388ed0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "e7834142e6c417b4",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-12T05:53:47.142030Z",
     "start_time": "2024-05-12T05:53:46.335842Z"
    }
   },
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.filters import unsharp_mask\n",
    "\n",
    "num_train_samples=500\n",
    "num_test_samples=int(0.2*num_train_samples)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T05:53:49.066941Z",
     "start_time": "2024-05-12T05:53:49.059034Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def remove_noise (image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    X = cv2.bilateralFilter(gray, 15, sigmaColor=10, sigmaSpace=10)\n",
    "    median = cv2.medianBlur(X, 5)\n",
    "    result_2 = unsharp_mask(median, radius=10, amount=4)*255\n",
    "    result_2 = np.uint8(result_2)\n",
    "    sharpen = cv2.Canny(result_2, 100,250)\n",
    "    return sharpen"
   ],
   "id": "97627c877d9c359d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-05-12T05:53:50.155999Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all_des=np.empty((1,128))\n",
    "\n",
    "sift = cv2.SIFT_create(500)\n",
    "\n",
    "num_of_desc=[]\n",
    "\n",
    "for i in range (num_train_samples):\n",
    "    image = cv2.imread(\"../../fonts-dataset/IBM Plex Sans Arabic/\"+str(i)+\".jpeg\")\n",
    "    removed_noise = remove_noise(image)\n",
    "    kp , descriptors= sift.detectAndCompute(removed_noise,None)\n",
    "    if descriptors is not None:\n",
    "        all_des=np.vstack((all_des,descriptors))\n",
    "    print(\"processing type 1 image\"+str(i))\n",
    "\n",
    "num_of_desc+=[all_des.shape[0]]\n",
    "print(\"FINISHED READING FIRST SET OF IMAGES\")\n",
    "\n",
    "for i in range (num_train_samples):\n",
    "    image = cv2.imread(\"../../fonts-dataset/Lemonada/\"+str(i)+\".jpeg\")\n",
    "    removed_noise = remove_noise(image)\n",
    "    kp , descriptors= sift.detectAndCompute(removed_noise,None)\n",
    "    if descriptors is not None:\n",
    "        all_des=np.vstack((all_des,descriptors))\n",
    "    print(\"processing type 2 image\"+str(i))\n",
    "\n",
    "num_of_desc+=[all_des.shape[0]]\n",
    "print(\"FINISHED READING SECOND SET OF IMAGES\")\n",
    "\n",
    "for i in range (num_train_samples):\n",
    "    image = cv2.imread(\"../../fonts-dataset/Marhey/\"+str(i)+\".jpeg\")\n",
    "    removed_noise = remove_noise(image)\n",
    "    kp , descriptors= sift.detectAndCompute(removed_noise,None)\n",
    "    if descriptors is not None:\n",
    "        all_des=np.vstack((all_des,descriptors))\n",
    "    print(\"processing type 3 image\"+str(i))\n",
    "\n",
    "num_of_desc+=[all_des.shape[0]]\n",
    "print(\"FINISHED READING THIRD SET OF IMAGES\")\n",
    "\n",
    "\n",
    "for i in range (num_train_samples):\n",
    "    image = cv2.imread(\"../../fonts-dataset/Scheherazade New/\"+str(i)+\".jpeg\")\n",
    "    removed_noise = remove_noise(image)\n",
    "    kp , descriptors= sift.detectAndCompute(removed_noise,None)\n",
    "    if descriptors is not None:\n",
    "        all_des=np.vstack((all_des,descriptors))\n",
    "    print(\"processing type 4 image\"+str(i))\n",
    "\n",
    "num_of_desc+=[all_des.shape[0]]\n",
    "print(\"FINISHED READING FOURTH SET OF IMAGES\")\n",
    "\n",
    "desc_labels=np.zeros(all_des.shape[0])\n",
    "desc_labels[num_of_desc[0]:num_of_desc[1]]=1\n",
    "desc_labels[num_of_desc[1]:num_of_desc[2]]=2\n",
    "desc_labels[num_of_desc[2]:num_of_desc[3]]=3"
   ],
   "id": "9d373dd32a33c8dd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing type 1 image0\n",
      "processing type 1 image1\n",
      "processing type 1 image2\n",
      "processing type 1 image3\n",
      "processing type 1 image4\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T02:32:15.605954Z",
     "start_time": "2024-05-12T02:12:38.654495Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_des, desc_labels, test_size=0.2, random_state=42)\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)"
   ],
   "id": "71393c92fe73ff2e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ],
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier()</pre></div> </div></div></div></div>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T03:18:01.338735Z",
     "start_time": "2024-05-12T02:51:26.319200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict_rf (descriptors, rf):\n",
    "    predictions = np.zeros(4)\n",
    "    for des in descriptors:\n",
    "        pred = rf.predict([des])\n",
    "        ind = np.int64(pred[0])\n",
    "        predictions[ind]+=1\n",
    "    return np.argmax(predictions)\n",
    "\n",
    "num_right0=0\n",
    "num_right1=0\n",
    "num_right2=0\n",
    "num_right3=0\n",
    "\n",
    "for i in range (num_test_samples):\n",
    "    image = cv2.imread(\"../../fonts-dataset/IBM Plex Sans Arabic/\"+str(num_train_samples+i)+\".jpeg\")\n",
    "    removed_noise = remove_noise(image)\n",
    "    kp , descriptors= sift.detectAndCompute(removed_noise,None)\n",
    "    if descriptors is not None:\n",
    "        predic = predict_rf(descriptors, rf)\n",
    "        num_right0 += predic==0\n",
    "        print(\"processing type 0 image\"+str(num_train_samples+i)+\" is \"+str(predic))\n",
    "\n",
    "print(\"FINISHED TESTING FIRST SET OF IMAGES\")\n",
    "\n",
    "for i in range (num_test_samples):\n",
    "    image = cv2.imread(\"../../fonts-dataset/Lemonada/\"+str(num_train_samples+i)+\".jpeg\")\n",
    "    removed_noise = remove_noise(image)\n",
    "    kp , descriptors= sift.detectAndCompute(removed_noise,None)\n",
    "    if descriptors is not None:\n",
    "        predic = predict_rf(descriptors, rf)\n",
    "        num_right1 += predic==1 \n",
    "        print(\"processing type 1 image\"+str(num_train_samples+i)+\" is \"+str(predic))  \n",
    "\n",
    "\n",
    "print(\"FINISHED TESTING SECOND SET OF IMAGES\")\n",
    "\n",
    "for i in range (num_test_samples):\n",
    "    image = cv2.imread(\"../../fonts-dataset/Marhey/\"+str(num_train_samples+i)+\".jpeg\")\n",
    "    removed_noise = remove_noise(image)\n",
    "    kp , descriptors= sift.detectAndCompute(removed_noise,None)\n",
    "    if descriptors is not None:\n",
    "        predic = predict_rf(descriptors, rf)\n",
    "        num_right2 += predic==2\n",
    "        print(\"processing type 2 image\"+str(num_train_samples+i)+\" is \"+str(predic))\n",
    "\n",
    "print(\"FINISHED TESTING THIRD SET OF IMAGES\")\n",
    "\n",
    "for i in range (num_test_samples):\n",
    "    image = cv2.imread(\"../../fonts-dataset/Scheherazade New/\"+str(num_train_samples+i)+\".jpeg\")\n",
    "    removed_noise = remove_noise(image)\n",
    "    kp , descriptors= sift.detectAndCompute(removed_noise,None)\n",
    "    if descriptors is not None:\n",
    "        predic = predict_rf(descriptors, rf)\n",
    "        num_right3 += predic==3\n",
    "        print(\"processing type 3 image\"+str(num_train_samples+i)+\" is \"+str(predic))\n",
    "\n",
    "print(\"FINISHED TESTING FOURTH SET OF IMAGES\")\n",
    "print(((num_right0+num_right1+num_right2+num_right3)/(4*num_test_samples))*100)"
   ],
   "id": "72050b149655c350",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing type 0 image200 is 0\n",
      "processing type 0 image201 is 0\n",
      "processing type 0 image202 is 2\n",
      "processing type 0 image203 is 0\n",
      "processing type 0 image204 is 0\n",
      "processing type 0 image205 is 0\n",
      "processing type 0 image206 is 0\n",
      "processing type 0 image207 is 0\n",
      "processing type 0 image208 is 0\n",
      "processing type 0 image209 is 0\n",
      "processing type 0 image210 is 0\n",
      "processing type 0 image211 is 0\n",
      "processing type 0 image212 is 0\n",
      "processing type 0 image213 is 0\n",
      "processing type 0 image214 is 0\n",
      "processing type 0 image215 is 0\n",
      "processing type 0 image216 is 0\n",
      "processing type 0 image217 is 0\n",
      "processing type 0 image218 is 0\n",
      "processing type 0 image219 is 0\n",
      "processing type 0 image220 is 0\n",
      "processing type 0 image221 is 0\n",
      "processing type 0 image222 is 0\n",
      "processing type 0 image223 is 0\n",
      "processing type 0 image224 is 0\n",
      "processing type 0 image225 is 0\n",
      "processing type 0 image226 is 0\n",
      "processing type 0 image227 is 0\n",
      "processing type 0 image228 is 0\n",
      "processing type 0 image229 is 0\n",
      "processing type 0 image230 is 0\n",
      "processing type 0 image231 is 0\n",
      "processing type 0 image232 is 0\n",
      "processing type 0 image233 is 0\n",
      "processing type 0 image234 is 0\n",
      "processing type 0 image235 is 0\n",
      "processing type 0 image236 is 0\n",
      "processing type 0 image237 is 0\n",
      "processing type 0 image238 is 0\n",
      "processing type 0 image239 is 0\n",
      "processing type 0 image240 is 0\n",
      "processing type 0 image241 is 0\n",
      "processing type 0 image242 is 2\n",
      "processing type 0 image243 is 0\n",
      "processing type 0 image244 is 0\n",
      "processing type 0 image245 is 0\n",
      "processing type 0 image246 is 2\n",
      "processing type 0 image247 is 0\n",
      "processing type 0 image248 is 0\n",
      "processing type 0 image249 is 0\n",
      "processing type 0 image250 is 0\n",
      "processing type 0 image251 is 0\n",
      "processing type 0 image252 is 0\n",
      "processing type 0 image253 is 0\n",
      "processing type 0 image254 is 0\n",
      "processing type 0 image255 is 0\n",
      "processing type 0 image256 is 0\n",
      "processing type 0 image257 is 0\n",
      "processing type 0 image258 is 0\n",
      "processing type 0 image259 is 0\n",
      "processing type 0 image260 is 0\n",
      "processing type 0 image261 is 0\n",
      "processing type 0 image262 is 0\n",
      "processing type 0 image263 is 0\n",
      "processing type 0 image264 is 0\n",
      "processing type 0 image265 is 0\n",
      "processing type 0 image266 is 0\n",
      "processing type 0 image267 is 0\n",
      "processing type 0 image268 is 0\n",
      "processing type 0 image269 is 2\n",
      "processing type 0 image270 is 0\n",
      "processing type 0 image271 is 0\n",
      "processing type 0 image272 is 0\n",
      "processing type 0 image273 is 0\n",
      "processing type 0 image274 is 0\n",
      "processing type 0 image275 is 0\n",
      "processing type 0 image276 is 0\n",
      "processing type 0 image277 is 0\n",
      "processing type 0 image278 is 0\n",
      "processing type 0 image279 is 0\n",
      "processing type 0 image280 is 0\n",
      "processing type 0 image281 is 2\n",
      "processing type 0 image282 is 0\n",
      "processing type 0 image283 is 0\n",
      "processing type 0 image284 is 0\n",
      "processing type 0 image285 is 0\n",
      "processing type 0 image286 is 0\n",
      "processing type 0 image287 is 0\n",
      "processing type 0 image288 is 0\n",
      "processing type 0 image289 is 0\n",
      "processing type 0 image290 is 0\n",
      "processing type 0 image291 is 0\n",
      "processing type 0 image292 is 0\n",
      "processing type 0 image293 is 0\n",
      "processing type 0 image294 is 0\n",
      "processing type 0 image295 is 0\n",
      "processing type 0 image296 is 0\n",
      "processing type 0 image297 is 0\n",
      "processing type 0 image298 is 0\n",
      "processing type 0 image299 is 0\n",
      "FINISHED TESTING FIRST SET OF IMAGES\n",
      "processing type 1 image200 is 1\n",
      "processing type 1 image201 is 1\n",
      "processing type 1 image202 is 1\n",
      "processing type 1 image203 is 1\n",
      "processing type 1 image204 is 1\n",
      "processing type 1 image205 is 1\n",
      "processing type 1 image206 is 1\n",
      "processing type 1 image207 is 1\n",
      "processing type 1 image208 is 1\n",
      "processing type 1 image209 is 1\n",
      "processing type 1 image210 is 1\n",
      "processing type 1 image211 is 1\n",
      "processing type 1 image212 is 1\n",
      "processing type 1 image213 is 1\n",
      "processing type 1 image214 is 1\n",
      "processing type 1 image215 is 1\n",
      "processing type 1 image216 is 1\n",
      "processing type 1 image217 is 1\n",
      "processing type 1 image218 is 1\n",
      "processing type 1 image219 is 1\n",
      "processing type 1 image220 is 1\n",
      "processing type 1 image221 is 1\n",
      "processing type 1 image222 is 1\n",
      "processing type 1 image223 is 1\n",
      "processing type 1 image224 is 1\n",
      "processing type 1 image225 is 1\n",
      "processing type 1 image226 is 1\n",
      "processing type 1 image227 is 1\n",
      "processing type 1 image228 is 1\n",
      "processing type 1 image229 is 1\n",
      "processing type 1 image230 is 2\n",
      "processing type 1 image231 is 1\n",
      "processing type 1 image232 is 1\n",
      "processing type 1 image233 is 1\n",
      "processing type 1 image234 is 1\n",
      "processing type 1 image235 is 1\n",
      "processing type 1 image236 is 1\n",
      "processing type 1 image237 is 1\n",
      "processing type 1 image238 is 1\n",
      "processing type 1 image239 is 1\n",
      "processing type 1 image240 is 1\n",
      "processing type 1 image241 is 1\n",
      "processing type 1 image242 is 1\n",
      "processing type 1 image243 is 1\n",
      "processing type 1 image244 is 2\n",
      "processing type 1 image245 is 0\n",
      "processing type 1 image246 is 1\n",
      "processing type 1 image247 is 1\n",
      "processing type 1 image248 is 1\n",
      "processing type 1 image249 is 1\n",
      "processing type 1 image250 is 1\n",
      "processing type 1 image251 is 1\n",
      "processing type 1 image252 is 1\n",
      "processing type 1 image253 is 1\n",
      "processing type 1 image254 is 1\n",
      "processing type 1 image255 is 1\n",
      "processing type 1 image256 is 1\n",
      "processing type 1 image257 is 1\n",
      "processing type 1 image258 is 1\n",
      "processing type 1 image259 is 1\n",
      "processing type 1 image260 is 1\n",
      "processing type 1 image261 is 1\n",
      "processing type 1 image262 is 1\n",
      "processing type 1 image263 is 1\n",
      "processing type 1 image264 is 1\n",
      "processing type 1 image265 is 1\n",
      "processing type 1 image266 is 1\n",
      "processing type 1 image267 is 1\n",
      "processing type 1 image268 is 1\n",
      "processing type 1 image269 is 0\n",
      "processing type 1 image270 is 1\n",
      "processing type 1 image271 is 1\n",
      "processing type 1 image272 is 1\n",
      "processing type 1 image273 is 1\n",
      "processing type 1 image274 is 1\n",
      "processing type 1 image275 is 1\n",
      "processing type 1 image276 is 1\n",
      "processing type 1 image277 is 1\n",
      "processing type 1 image278 is 1\n",
      "processing type 1 image279 is 1\n",
      "processing type 1 image280 is 1\n",
      "processing type 1 image281 is 1\n",
      "processing type 1 image282 is 1\n",
      "processing type 1 image283 is 1\n",
      "processing type 1 image284 is 1\n",
      "processing type 1 image285 is 1\n",
      "processing type 1 image286 is 1\n",
      "processing type 1 image287 is 1\n",
      "processing type 1 image288 is 1\n",
      "processing type 1 image289 is 1\n",
      "processing type 1 image290 is 1\n",
      "processing type 1 image291 is 1\n",
      "processing type 1 image292 is 1\n",
      "processing type 1 image293 is 1\n",
      "processing type 1 image294 is 1\n",
      "processing type 1 image295 is 1\n",
      "processing type 1 image296 is 1\n",
      "processing type 1 image297 is 1\n",
      "processing type 1 image298 is 1\n",
      "processing type 1 image299 is 1\n",
      "FINISHED TESTING SECOND SET OF IMAGES\n",
      "processing type 2 image200 is 2\n",
      "processing type 2 image201 is 2\n",
      "processing type 2 image202 is 2\n",
      "processing type 2 image203 is 2\n",
      "processing type 2 image204 is 2\n",
      "processing type 2 image205 is 2\n",
      "processing type 2 image206 is 2\n",
      "processing type 2 image207 is 2\n",
      "processing type 2 image208 is 2\n",
      "processing type 2 image209 is 2\n",
      "processing type 2 image210 is 2\n",
      "processing type 2 image211 is 2\n",
      "processing type 2 image212 is 2\n",
      "processing type 2 image213 is 2\n",
      "processing type 2 image214 is 2\n",
      "processing type 2 image215 is 2\n",
      "processing type 2 image216 is 2\n",
      "processing type 2 image217 is 2\n",
      "processing type 2 image218 is 2\n",
      "processing type 2 image219 is 2\n",
      "processing type 2 image220 is 2\n",
      "processing type 2 image221 is 2\n",
      "processing type 2 image222 is 2\n",
      "processing type 2 image223 is 2\n",
      "processing type 2 image224 is 2\n",
      "processing type 2 image225 is 2\n",
      "processing type 2 image226 is 2\n",
      "processing type 2 image227 is 2\n",
      "processing type 2 image228 is 2\n",
      "processing type 2 image229 is 2\n",
      "processing type 2 image230 is 2\n",
      "processing type 2 image231 is 2\n",
      "processing type 2 image232 is 2\n",
      "processing type 2 image233 is 2\n",
      "processing type 2 image234 is 2\n",
      "processing type 2 image235 is 2\n",
      "processing type 2 image236 is 2\n",
      "processing type 2 image237 is 2\n",
      "processing type 2 image238 is 2\n",
      "processing type 2 image239 is 2\n",
      "processing type 2 image240 is 2\n",
      "processing type 2 image241 is 2\n",
      "processing type 2 image242 is 2\n",
      "processing type 2 image243 is 2\n",
      "processing type 2 image244 is 2\n",
      "processing type 2 image245 is 2\n",
      "processing type 2 image246 is 2\n",
      "processing type 2 image247 is 2\n",
      "processing type 2 image248 is 2\n",
      "processing type 2 image249 is 2\n",
      "processing type 2 image250 is 2\n",
      "processing type 2 image251 is 2\n",
      "processing type 2 image252 is 2\n",
      "processing type 2 image253 is 2\n",
      "processing type 2 image254 is 2\n",
      "processing type 2 image255 is 2\n",
      "processing type 2 image256 is 2\n",
      "processing type 2 image257 is 2\n",
      "processing type 2 image258 is 2\n",
      "processing type 2 image259 is 2\n",
      "processing type 2 image260 is 2\n",
      "processing type 2 image261 is 2\n",
      "processing type 2 image262 is 2\n",
      "processing type 2 image263 is 2\n",
      "processing type 2 image264 is 2\n",
      "processing type 2 image265 is 2\n",
      "processing type 2 image266 is 2\n",
      "processing type 2 image267 is 2\n",
      "processing type 2 image268 is 2\n",
      "processing type 2 image269 is 2\n",
      "processing type 2 image270 is 2\n",
      "processing type 2 image271 is 2\n",
      "processing type 2 image272 is 2\n",
      "processing type 2 image273 is 2\n",
      "processing type 2 image274 is 2\n",
      "processing type 2 image275 is 2\n",
      "processing type 2 image276 is 2\n",
      "processing type 2 image277 is 2\n",
      "processing type 2 image278 is 2\n",
      "processing type 2 image279 is 2\n",
      "processing type 2 image280 is 2\n",
      "processing type 2 image281 is 2\n",
      "processing type 2 image282 is 2\n",
      "processing type 2 image283 is 2\n",
      "processing type 2 image284 is 2\n",
      "processing type 2 image285 is 2\n",
      "processing type 2 image286 is 2\n",
      "processing type 2 image287 is 2\n",
      "processing type 2 image288 is 2\n",
      "processing type 2 image289 is 2\n",
      "processing type 2 image290 is 2\n",
      "processing type 2 image291 is 2\n",
      "processing type 2 image292 is 2\n",
      "processing type 2 image293 is 2\n",
      "processing type 2 image294 is 2\n",
      "processing type 2 image295 is 2\n",
      "processing type 2 image296 is 2\n",
      "processing type 2 image297 is 2\n",
      "processing type 2 image298 is 2\n",
      "processing type 2 image299 is 2\n",
      "FINISHED TESTING THIRD SET OF IMAGES\n",
      "processing type 3 image200 is 3\n",
      "processing type 3 image201 is 3\n",
      "processing type 3 image202 is 3\n",
      "processing type 3 image203 is 3\n",
      "processing type 3 image204 is 3\n",
      "processing type 3 image205 is 3\n",
      "processing type 3 image206 is 3\n",
      "processing type 3 image207 is 3\n",
      "processing type 3 image208 is 3\n",
      "processing type 3 image209 is 1\n",
      "processing type 3 image210 is 3\n",
      "processing type 3 image211 is 3\n",
      "processing type 3 image212 is 3\n",
      "processing type 3 image213 is 3\n",
      "processing type 3 image214 is 3\n",
      "processing type 3 image215 is 3\n",
      "processing type 3 image216 is 3\n",
      "processing type 3 image217 is 2\n",
      "processing type 3 image218 is 3\n",
      "processing type 3 image219 is 3\n",
      "processing type 3 image220 is 2\n",
      "processing type 3 image221 is 3\n",
      "processing type 3 image222 is 3\n",
      "processing type 3 image223 is 3\n",
      "processing type 3 image224 is 3\n",
      "processing type 3 image225 is 3\n",
      "processing type 3 image226 is 3\n",
      "processing type 3 image227 is 3\n",
      "processing type 3 image228 is 3\n",
      "processing type 3 image229 is 2\n",
      "processing type 3 image230 is 3\n",
      "processing type 3 image231 is 3\n",
      "processing type 3 image232 is 3\n",
      "processing type 3 image233 is 3\n",
      "processing type 3 image234 is 3\n",
      "processing type 3 image235 is 3\n",
      "processing type 3 image236 is 2\n",
      "processing type 3 image237 is 3\n",
      "processing type 3 image238 is 3\n",
      "processing type 3 image239 is 3\n",
      "processing type 3 image240 is 3\n",
      "processing type 3 image241 is 3\n",
      "processing type 3 image242 is 3\n",
      "processing type 3 image243 is 3\n",
      "processing type 3 image244 is 2\n",
      "processing type 3 image245 is 3\n",
      "processing type 3 image246 is 3\n",
      "processing type 3 image247 is 3\n",
      "processing type 3 image248 is 3\n",
      "processing type 3 image249 is 3\n",
      "processing type 3 image250 is 3\n",
      "processing type 3 image251 is 3\n",
      "processing type 3 image252 is 3\n",
      "processing type 3 image253 is 3\n",
      "processing type 3 image254 is 3\n",
      "processing type 3 image255 is 3\n",
      "processing type 3 image256 is 3\n",
      "processing type 3 image257 is 3\n",
      "processing type 3 image258 is 3\n",
      "processing type 3 image259 is 3\n",
      "processing type 3 image260 is 3\n",
      "processing type 3 image261 is 3\n",
      "processing type 3 image262 is 3\n",
      "processing type 3 image263 is 3\n",
      "processing type 3 image264 is 3\n",
      "processing type 3 image265 is 3\n",
      "processing type 3 image266 is 3\n",
      "processing type 3 image267 is 2\n",
      "processing type 3 image268 is 3\n",
      "processing type 3 image269 is 3\n",
      "processing type 3 image270 is 3\n",
      "processing type 3 image271 is 3\n",
      "processing type 3 image272 is 3\n",
      "processing type 3 image273 is 3\n",
      "processing type 3 image274 is 3\n",
      "processing type 3 image275 is 2\n",
      "processing type 3 image276 is 3\n",
      "processing type 3 image277 is 3\n",
      "processing type 3 image278 is 3\n",
      "processing type 3 image279 is 3\n",
      "processing type 3 image280 is 3\n",
      "processing type 3 image281 is 3\n",
      "processing type 3 image282 is 3\n",
      "processing type 3 image283 is 3\n",
      "processing type 3 image284 is 3\n",
      "processing type 3 image285 is 3\n",
      "processing type 3 image286 is 3\n",
      "processing type 3 image287 is 3\n",
      "processing type 3 image288 is 3\n",
      "processing type 3 image289 is 3\n",
      "processing type 3 image290 is 3\n",
      "processing type 3 image291 is 3\n",
      "processing type 3 image292 is 3\n",
      "processing type 3 image293 is 3\n",
      "processing type 3 image294 is 3\n",
      "processing type 3 image295 is 3\n",
      "processing type 3 image296 is 3\n",
      "processing type 3 image297 is 2\n",
      "processing type 3 image298 is 3\n",
      "processing type 3 image299 is 2\n",
      "FINISHED TESTING FOURTH SET OF IMAGES\n",
      "95.25\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3b7123b461aebf8e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41c4f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sift feature from the image\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import random\n",
    "\n",
    "num_of_centroids=4096\n",
    "num_train_samples=300\n",
    "num_test_samples=100\n",
    "\n",
    "all_image_idx=random.sample(range(0,400),400)\n",
    "\n",
    "def remove_noise (image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    median = cv2.medianBlur(gray, 3)\n",
    "    sharpen = cv2.Canny(median, 100,250)\n",
    "    return sharpen\n",
    "\n",
    "\n",
    "def show_images(images, titles=None):\n",
    "    n_ims = len(images)\n",
    "    if titles is None:\n",
    "        titles = ['(%d)' % i for i in range(1, n_ims + 1)]\n",
    "    fig = plt.figure()\n",
    "    n = 1\n",
    "    for image, title in zip(images, titles):\n",
    "        a = fig.add_subplot(1, n_ims, n)\n",
    "        if image.ndim == 2:\n",
    "            plt.gray()\n",
    "        plt.imshow(image)\n",
    "        a.set_title(title)\n",
    "        n += 1\n",
    "    fig.set_size_inches(np.array(fig.get_size_inches()) * n_ims)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T21:15:00.283514Z",
     "start_time": "2024-05-04T21:14:59.455725Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "all_des=np.empty((1,128))\n",
    "\n",
    "#SIFT\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "num_of_desc=[]\n",
    "\n",
    "for i in range (num_train_samples):\n",
    "    image = cv2.imread(\"../../fonts-dataset/IBM Plex Sans Arabic/\"+str(all_image_idx[i])+\".jpeg\")\n",
    "    removed_noise = remove_noise(image)\n",
    "    kp , descriptors= sift.detectAndCompute(removed_noise,None)\n",
    "    if descriptors is not None:\n",
    "        all_des=np.vstack((all_des,descriptors))\n",
    "    print(\"processing type 1 image\"+str(i))\n",
    "\n",
    "\n",
    "num_of_desc+=[all_des.shape[0]]\n",
    "print(\"FINISHED READING FIRST SET OF IMAGES\")\n",
    "\n",
    "for i in range (num_train_samples):\n",
    "    image = cv2.imread(\"../../fonts-dataset/Lemonada/\"+str(all_image_idx[i])+\".jpeg\")\n",
    "    removed_noise = remove_noise(image)\n",
    "    kp , descriptors= sift.detectAndCompute(removed_noise,None)\n",
    "    if descriptors is not None:\n",
    "        all_des=np.vstack((all_des,descriptors))\n",
    "    print(\"processing type 2 image\"+str(i))\n",
    "\n",
    "num_of_desc+=[all_des.shape[0]]\n",
    "\n",
    "print(\"FINISHED READING SECOND SET OF IMAGES\")\n",
    "\n",
    "for i in range (num_train_samples):\n",
    "    image = cv2.imread(\"../../fonts-dataset/Marhey/\"+str(all_image_idx[i])+\".jpeg\")\n",
    "    removed_noise = remove_noise(image)\n",
    "    kp , descriptors= sift.detectAndCompute(removed_noise,None)\n",
    "    if descriptors is not None:\n",
    "        all_des=np.vstack((all_des,descriptors))\n",
    "    print(\"processing type 3 image\"+str(i))\n",
    "\n",
    "num_of_desc+=[all_des.shape[0]]\n",
    "print(\"FINISHED READING THIRD SET OF IMAGES\")\n",
    "\n",
    "\n",
    "for i in range (num_train_samples):\n",
    "    image = cv2.imread(\"../../fonts-dataset/Scheherazade New/\"+str(all_image_idx[i])+\".jpeg\")\n",
    "    removed_noise = remove_noise(image)\n",
    "    kp , descriptors= sift.detectAndCompute(removed_noise,None)\n",
    "    if descriptors is not None:\n",
    "        all_des=np.vstack((all_des,descriptors))\n",
    "    print(\"processing type 4 image\"+str(i))\n",
    "\n",
    "num_of_desc+=[all_des.shape[0]]\n",
    "print(\"FINISHED READING FOURTH SET OF IMAGES\")\n",
    "\n",
    "desc_labels=np.zeros(all_des.shape[0])\n",
    "desc_labels[num_of_desc[0]:num_of_desc[1]]=1\n",
    "desc_labels[num_of_desc[1]+1:num_of_desc[2]]=2\n",
    "desc_labels[num_of_desc[2]+1:num_of_desc[3]]=3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f91073a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# different options for kmeans\n",
    "# - mini batches\n",
    "# - limiting the number of descriptors\n",
    "kmeans=MiniBatchKMeans(n_clusters=num_of_centroids,batch_size=num_of_centroids*1024,max_iter=20).fit(X=all_des)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d51216",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kmeans.cluster_centers_.shape)\n",
    "print(kmeans.labels_.shape)\n",
    "print(desc_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56736328253ed568",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids_labels=np.zeros((num_of_centroids,4))\n",
    "for i in range(num_of_centroids):\n",
    "    centroids_labels[i][0]=(np.sum(desc_labels[kmeans.labels_==i]==0))\n",
    "    centroids_labels[i][1]=(np.sum(desc_labels[kmeans.labels_==i]==1))\n",
    "    centroids_labels[i][2]=(np.sum(desc_labels[kmeans.labels_==i]==2))\n",
    "    centroids_labels[i][3]=(np.sum(desc_labels[kmeans.labels_==i]==3))\n",
    "    centroids_labels[i]/=np.sum(centroids_labels[i])\n",
    "    \n",
    "    \n",
    "    \n",
    "with open('kmeans_centers.txt', 'wb') as f:\n",
    "    np.save(f, kmeans.cluster_centers_)\n",
    "\n",
    "\n",
    "with open('kmeans_labels.txt', 'wb') as f:\n",
    "    np.save(f, centroids_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c90d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def predict(path,centroids,centroids_labels):\n",
    "    image=cv2.imread(path)\n",
    "    removed_noise = remove_noise(image)\n",
    "    _ , descriptors= sift.detectAndCompute(removed_noise,None)\n",
    "\n",
    "    predections=[0.0,0.0,0.0,0.0]\n",
    "    if descriptors is not None:\n",
    "        for des in descriptors:\n",
    "            idx=kmeans.predict([des])\n",
    "            dist=np.linalg.norm(des-centroids[i])\n",
    "            predections+=(centroids_labels[idx]/dist)\n",
    "        return np.argmax(predections)\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "num_right0=0\n",
    "num_right1=0\n",
    "num_right2=0\n",
    "num_right3=0\n",
    "\n",
    "for i in range (num_test_samples):\n",
    "    rand_idx=str(all_image_idx[num_train_samples+i])\n",
    "    path=\"../../fonts-dataset/IBM Plex Sans Arabic/\"+rand_idx+\".jpeg\"\n",
    "      \n",
    "    predicted=predict(path,kmeans.cluster_centers_,centroids_labels)\n",
    "    print(\"image\",(rand_idx), \"type0: \",predicted)\n",
    "    num_right0+=predicted==0\n",
    "\n",
    "for i in range (num_test_samples):\n",
    "    rand_idx=str(all_image_idx[num_train_samples+i])\n",
    "    path=\"../../fonts-dataset/Lemonada/\"+rand_idx+\".jpeg\"\n",
    "    \n",
    "    predicted=predict(path,kmeans.cluster_centers_,centroids_labels)\n",
    "    print(\"image\",(rand_idx), \"type1: \",predicted)\n",
    "    num_right1+=predicted==1\n",
    "    \n",
    "for i in range (num_test_samples):\n",
    "    rand_idx=str(all_image_idx[num_train_samples+i])\n",
    "\n",
    "    path=\"../../fonts-dataset/Marhey/\"+rand_idx+\".jpeg\"\n",
    "      \n",
    "    predicted=predict(path,kmeans.cluster_centers_,centroids_labels)\n",
    "    print(\"image\",(rand_idx), \"type2: \",predicted)\n",
    "    num_right2+=predicted==2\n",
    "    \n",
    "for i in range (num_test_samples):\n",
    "    rand_idx=str(all_image_idx[num_train_samples+i])\n",
    "\n",
    "    path=\"../../fonts-dataset/Scheherazade New/\"+rand_idx+\".jpeg\"\n",
    "      \n",
    "    predicted=predict(path,kmeans.cluster_centers_,centroids_labels)\n",
    "    print(\"image\",(rand_idx), \"type3: \",predicted)\n",
    "    num_right3+=predicted==3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bff3693",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(num_right0)\n",
    "print(num_right1)\n",
    "print(num_right2)\n",
    "print(num_right3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c4586a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(num_right0+num_right1+num_right2+num_right3)/400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc0ca1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread(\"../../fonts-dataset/Marhey/233.jpeg\")\n",
    "removed_noise=remove_noise(img)\n",
    "_ , descriptors= sift.detectAndCompute(removed_noise,None)\n",
    "\n",
    "predections=[0.0,0.0,0.0,0.0]\n",
    "for des in descriptors:\n",
    "    idx=kmeans.predict([des])\n",
    "    dist=np.linalg.norm(des-kmeans.cluster_centers_[i])\n",
    "    predections+=(centroids_labels[idx]/dist)\n",
    "print(predections)\n",
    "\n",
    "show_images([removed_noise])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3c8abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=9)\n",
    "classes=np.arange(0, num_of_centroids, 1, dtype=int)\n",
    "knn.fit(kmeans.cluster_centers_,classes)\n",
    "_ , descriptors= sift.detectAndCompute(removed_noise,None)\n",
    "\n",
    "predections=[0.0,0.0,0.0,0.0]\n",
    "for des in descriptors:\n",
    "    idx=knn.predict([des])\n",
    "    dist=np.linalg.norm(des-kmeans.cluster_centers_[i])\n",
    "    predections+=(centroids_labels[idx]/dist)\n",
    "print(predections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50967f84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

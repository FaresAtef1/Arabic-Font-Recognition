{
 "cells": [
  {
   "cell_type": "code",
   "id": "c41c4f02",
   "metadata": {},
   "source": [
    "# Extract sift feature from the image\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import random\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "\n",
    "\n",
    "num_of_centroids=4096\n",
    "num_train_samples=300\n",
    "num_test_samples=100\n",
    "\n",
    "all_image_idx=random.sample(range(0,400),400)\n",
    "\n",
    "def remove_noise (image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    median = cv2.medianBlur(gray, 3)\n",
    "    sharpen = cv2.Canny(median, 100,250)\n",
    "    return sharpen\n",
    "\n",
    "\n",
    "def show_images(images, titles=None):\n",
    "    n_ims = len(images)\n",
    "    if titles is None:\n",
    "        titles = ['(%d)' % i for i in range(1, n_ims + 1)]\n",
    "    fig = plt.figure()\n",
    "    n = 1\n",
    "    for image, title in zip(images, titles):\n",
    "        a = fig.add_subplot(1, n_ims, n)\n",
    "        if image.ndim == 2:\n",
    "            plt.gray()\n",
    "        plt.imshow(image)\n",
    "        a.set_title(title)\n",
    "        n += 1\n",
    "    fig.set_size_inches(np.array(fig.get_size_inches()) * n_ims)\n",
    "    plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "NUM_OF_DESCRIPTORS_PER_IMAGE = 200\n",
    "\n",
    "all_des=np.empty((1,128))\n",
    "labels = np.array([])\n",
    "\n",
    "#SIFT\n",
    "sift = cv2.SIFT_create()\n",
    "for i in range (100):\n",
    "    image = cv2.imread(\"../../fonts-dataset/Lemonada/\"+str(i)+\".jpeg\")\n",
    "    removed_noise = remove_noise(image)\n",
    "    kp , descriptors= sift.detectAndCompute(removed_noise,None)\n",
    "\n",
    "    scores= [p.response for p in kp]\n",
    "    sorted_indices = np.argsort(scores)[::-1]\n",
    "    sorted_keypoints = [kp[i] for i in sorted_indices]\n",
    "    sorted_descriptors = descriptors[sorted_indices[0:NUM_OF_DESCRIPTORS_PER_IMAGE]]\n",
    "    \n",
    "    print(sorted_descriptors.shape)\n",
    "    if sorted_descriptors is not None :\n",
    "        all_des=np.vstack((all_des,sorted_descriptors))\n",
    "        labels=np.append(labels,0)\n",
    "    \n",
    "    image2 = cv2.imread(\"../../fonts-dataset/Marhey/\"+str(i)+\".jpeg\")\n",
    "    removed_noise2 = remove_noise(image2)\n",
    "    kp , descriptors= sift.detectAndCompute(removed_noise2,None)\n",
    "\n",
    "    scores= [p.response for p in kp]\n",
    "    sorted_indices = np.argsort(scores)[::-1]\n",
    "    sorted_keypoints = [kp[i] for i in sorted_indices]\n",
    "    sorted_descriptors = descriptors[sorted_indices[0:NUM_OF_DESCRIPTORS_PER_IMAGE]]\n",
    "\n",
    "    if sorted_descriptors is not None :\n",
    "        all_des=np.vstack((all_des,sorted_descriptors))\n",
    "        labels=np.append(labels,1)\n",
    "\n",
    "    image3 = cv2.imread(\"../../fonts-dataset/IBM Plex Sans Arabic/\"+str(i)+\".jpeg\")\n",
    "    removed_noise3 = remove_noise(image3)\n",
    "    kp , descriptors= sift.detectAndCompute(removed_noise3,None)\n",
    "\n",
    "    scores= [p.response for p in kp]\n",
    "    sorted_indices = np.argsort(scores)[::-1]\n",
    "    sorted_keypoints = [kp[i] for i in sorted_indices]\n",
    "    sorted_descriptors = descriptors[sorted_indices[0:NUM_OF_DESCRIPTORS_PER_IMAGE]]\n",
    "\n",
    "    if sorted_descriptors is not None :\n",
    "        all_des=np.vstack((all_des,sorted_descriptors))\n",
    "        labels=np.append(labels,2)\n",
    "\n",
    "    image4 = cv2.imread(\"../../fonts-dataset/Scheherazade New/\"+str(i)+\".jpeg\")\n",
    "    removed_noise4 = remove_noise(image4)\n",
    "    kp , descriptors= sift.detectAndCompute(removed_noise4,None)\n",
    "\n",
    "    scores= [p.response for p in kp]\n",
    "    sorted_indices = np.argsort(scores)[::-1]\n",
    "    sorted_keypoints = [kp[i] for i in sorted_indices]\n",
    "    sorted_descriptors = descriptors[sorted_indices[0:NUM_OF_DESCRIPTORS_PER_IMAGE]]\n",
    "\n",
    "    if sorted_descriptors is not None :\n",
    "        all_des=np.vstack((all_des,sorted_descriptors))\n",
    "        labels=np.append(labels,3)\n",
    "    \n",
    "    print(i)\n",
    "\n",
    "print((all_des).shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_des, labels, test_size=0.2, random_state=42)\n",
    "kmeans=KMeans(n_clusters=4).fit(all_des)\n",
    "\n",
    "img=cv2.drawKeypoints(removed_noise,kp,image)\n",
    "show_images([img])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "56736328253ed568",
   "metadata": {},
   "source": [
    "# Temp\n",
    "x=remove_noise(cv2.imread(\"../../fonts-dataset/Lemonada/19.jpeg\"))\n",
    "res=cv2.findContours(x,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
    "conts=res[-2]\n",
    "image2=cv2.fillPoly(x,pts=conts,color=(255,255,255))\n",
    "show_images([image])\n",
    "kp , descriptors= sift.detectAndCompute(image2,None)\n",
    "img2=cv2.drawKeypoints(image2,kp,image)\n",
    "show_images([img])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# now use a classifier to classify the images, lets try SVM \n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X=[]\n",
    "y=[]\n",
    "\n",
    "for i in range (800 , 1000):\n",
    "    image = cv2.imread(\"../../fonts-dataset/Lemonada/\"+str(i)+\".jpeg\")\n",
    "    removed_noise = remove_noise(image)\n",
    "    kp , descriptors= sift.detectAndCompute(removed_noise,None)\n",
    "    if descriptors is not None:\n",
    "        hist=np.zeros(4)\n",
    "        for des in descriptors:\n",
    "            idx=kmeans.predict([des])\n",
    "            hist[idx]+=1\n",
    "        X.append(hist)\n",
    "        y.append(0)\n",
    "\n",
    "    image2 = cv2.imread(\"../../fonts-dataset/Marhey/\"+str(i)+\".jpeg\")\n",
    "    removed_noise2 = remove_noise(image2)\n",
    "    kp , descriptors= sift.detectAndCompute(removed_noise2,None)\n",
    "    if descriptors is not None:\n",
    "        hist=np.zeros(4)\n",
    "        for des in descriptors:\n",
    "            idx=kmeans.predict([des])\n",
    "            hist[idx]+=1\n",
    "        X.append(hist)\n",
    "        y.append(1)\n",
    "\n",
    "    image3 = cv2.imread(\"../../fonts-dataset/IBM Plex Sans Arabic/\"+str(i)+\".jpeg\")\n",
    "    removed_noise3 = remove_noise(image3)\n",
    "    kp , descriptors= sift.detectAndCompute(removed_noise3,None)\n",
    "    if descriptors is not None:\n",
    "        hist=np.zeros(4)\n",
    "        for des in descriptors:\n",
    "            idx=kmeans.predict([des])\n",
    "            hist[idx]+=1\n",
    "        X.append(hist)\n",
    "        y.append(2)\n",
    "\n",
    "    image4 = cv2.imread(\"../../fonts-dataset/Scheherazade New/\"+str(i)+\".jpeg\")\n",
    "    removed_noise4 = remove_noise(image4)\n",
    "    kp , descriptors= sift.detectAndCompute(removed_noise4,None)\n",
    "    if descriptors is not None:\n",
    "        hist=np.zeros(4)\n",
    "        for des in descriptors:\n",
    "            idx=kmeans.predict([des])\n",
    "            hist[idx]+=1\n",
    "        X.append(hist)\n",
    "        y.append(3)\n",
    "\n",
    "X=np.array(X)\n",
    "y=np.array(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred=clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)"
   ],
   "id": "1d6cf2a239c93a23",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "svm = SVC(kernel='poly', C=0.1, random_state=0, coef0=1, degree=4, gamma=10.0,class_weight= None)\n",
    "x_train = [[1],[2],[3],[4],[5],[6],[7],[8],[9],[10]]\n",
    "y_train = [1,2,3,4,5,6,7,8,9,10]\n",
    "x_test  = [[1],[2],[3],[4],[5],[6],[7],[8],[9],[10]]\n",
    "y_test = [1,2,3,4,5,6,7,8,9,10]\n",
    "svm.fit(x_train, y_train)\n",
    "y_pred = svm.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)\n"
   ],
   "id": "6bd32180e8d081e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "## KNN\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "NUM_OF_DESCRIPTORS_PER_IMAGE = 400\n",
    "NUMBER_OF_ITERATIONS = 100\n",
    "\n",
    "counter = 0\n",
    "\n",
    "all_des= []\n",
    "labels = np.array([])\n",
    "\n",
    "#SIFT\n",
    "sift = cv2.SIFT_create()\n",
    "for i in range (NUMBER_OF_ITERATIONS):\n",
    "    image = cv2.imread(\"../../fonts-dataset/Lemonada/\"+str(i)+\".jpeg\")\n",
    "    removed_noise = remove_noise(image)\n",
    "    kp , descriptors= sift.detectAndCompute(removed_noise,None)\n",
    "\n",
    "    scores= [p.response for p in kp]\n",
    "    sorted_indices = np.argsort(scores)[::-1]\n",
    "    sorted_keypoints = [kp[i] for i in sorted_indices]\n",
    "    sorted_descriptors = descriptors[sorted_indices[0:NUM_OF_DESCRIPTORS_PER_IMAGE]]\n",
    "    sorted_descriptors = sorted_descriptors.reshape(1,-1)\n",
    "    \n",
    "    if (sorted_descriptors is not None) and  sorted_descriptors.shape[1] == 128*NUM_OF_DESCRIPTORS_PER_IMAGE:\n",
    "        all_des.append(sorted_descriptors)\n",
    "        labels=np.append(labels,0)\n",
    "    else:\n",
    "        counter+=1\n",
    "\n",
    "    image2 = cv2.imread(\"../../fonts-dataset/Marhey/\"+str(i)+\".jpeg\")\n",
    "    removed_noise2 = remove_noise(image2)\n",
    "    kp , descriptors= sift.detectAndCompute(removed_noise2,None)\n",
    "\n",
    "    scores= [p.response for p in kp]\n",
    "    sorted_indices = np.argsort(scores)[::-1]\n",
    "    sorted_keypoints = [kp[i] for i in sorted_indices]\n",
    "    sorted_descriptors = descriptors[sorted_indices[0:NUM_OF_DESCRIPTORS_PER_IMAGE]]\n",
    "    ## reshape the sorted_descriptors to 1D array\n",
    "    sorted_descriptors = sorted_descriptors.reshape(1,-1)\n",
    "\n",
    "    if (sorted_descriptors is not None) and  sorted_descriptors.shape[1] == 128*NUM_OF_DESCRIPTORS_PER_IMAGE:\n",
    "        all_des.append(sorted_descriptors)\n",
    "        labels=np.append(labels,1)\n",
    "    else:\n",
    "        counter+=1\n",
    "\n",
    "    image3 = cv2.imread(\"../../fonts-dataset/IBM Plex Sans Arabic/\"+str(i)+\".jpeg\")\n",
    "    removed_noise3 = remove_noise(image3)\n",
    "    kp , descriptors= sift.detectAndCompute(removed_noise3,None)\n",
    "\n",
    "    scores= [p.response for p in kp]\n",
    "    sorted_indices = np.argsort(scores)[::-1]\n",
    "    sorted_keypoints = [kp[i] for i in sorted_indices]\n",
    "    sorted_descriptors = descriptors[sorted_indices[0:NUM_OF_DESCRIPTORS_PER_IMAGE]]\n",
    "    sorted_descriptors = sorted_descriptors.reshape(1,-1)\n",
    "\n",
    "    if (sorted_descriptors is not None) and  sorted_descriptors.shape[1] == 128*NUM_OF_DESCRIPTORS_PER_IMAGE:\n",
    "        all_des.append(sorted_descriptors)\n",
    "        labels=np.append(labels,2)\n",
    "    else:\n",
    "        counter+=1\n",
    "\n",
    "    image4 = cv2.imread(\"../../fonts-dataset/Scheherazade New/\"+str(i)+\".jpeg\")\n",
    "    removed_noise4 = remove_noise(image4)\n",
    "    kp , descriptors= sift.detectAndCompute(removed_noise4,None)\n",
    "\n",
    "    scores= [p.response for p in kp]\n",
    "    sorted_indices = np.argsort(scores)[::-1]\n",
    "    sorted_keypoints = [kp[i] for i in sorted_indices]\n",
    "    sorted_descriptors = descriptors[sorted_indices[0:NUM_OF_DESCRIPTORS_PER_IMAGE]]\n",
    "    sorted_descriptors = sorted_descriptors.reshape(1,-1)\n",
    "\n",
    "    if (sorted_descriptors is not None) and  sorted_descriptors.shape[1] == 128*NUM_OF_DESCRIPTORS_PER_IMAGE:\n",
    "        all_des.append(sorted_descriptors)\n",
    "        labels=np.append(labels,3)\n",
    "    else:\n",
    "        counter+=1\n",
    "\n",
    "    print(i)\n",
    "\n",
    "print(len(all_des)) # 100*4, 200*128\n",
    "# convert the list to numpy array\n",
    "all_des = np.array(all_des)\n",
    "print(all_des.shape)\n",
    "## reshape the all_des to 2D array\n",
    "all_des = all_des.reshape(NUMBER_OF_ITERATIONS*4 -counter, 128*NUM_OF_DESCRIPTORS_PER_IMAGE)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_des, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=11)\n",
    "tree = clf.fit(X_train, y_train)\n",
    "results = tree.predict(X_test)\n",
    "print(accuracy_score(y_test, results)*100)"
   ],
   "id": "a5350a0dd1fd037b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "all_des=np.empty((1,128))\n",
    "\n",
    "#SIFT\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "num_of_desc=[]\n",
    "\n",
    "for i in range (num_train_samples):\n",
    "    image = cv2.imread(\"../../fonts-dataset/IBM Plex Sans Arabic/\"+str(all_image_idx[i])+\".jpeg\")\n",
    "    removed_noise = remove_noise(image)\n",
    "    kp , descriptors= sift.detectAndCompute(removed_noise,None)\n",
    "    if descriptors is not None:\n",
    "        all_des=np.vstack((all_des,descriptors))\n",
    "    print(\"processing type 1 image\"+str(i))\n",
    "\n",
    "\n",
    "num_of_desc+=[all_des.shape[0]]\n",
    "print(\"FINISHED READING FIRST SET OF IMAGES\")\n",
    "\n",
    "for i in range (num_train_samples):\n",
    "    image = cv2.imread(\"../../fonts-dataset/Lemonada/\"+str(all_image_idx[i])+\".jpeg\")\n",
    "    removed_noise = remove_noise(image)\n",
    "    kp , descriptors= sift.detectAndCompute(removed_noise,None)\n",
    "    if descriptors is not None:\n",
    "        all_des=np.vstack((all_des,descriptors))\n",
    "    print(\"processing type 2 image\"+str(i))\n",
    "\n",
    "num_of_desc+=[all_des.shape[0]]\n",
    "\n",
    "print(\"FINISHED READING SECOND SET OF IMAGES\")\n",
    "\n",
    "for i in range (num_train_samples):\n",
    "    image = cv2.imread(\"../../fonts-dataset/Marhey/\"+str(all_image_idx[i])+\".jpeg\")\n",
    "    removed_noise = remove_noise(image)\n",
    "    kp , descriptors= sift.detectAndCompute(removed_noise,None)\n",
    "    if descriptors is not None:\n",
    "        all_des=np.vstack((all_des,descriptors))\n",
    "    print(\"processing type 3 image\"+str(i))\n",
    "\n",
    "num_of_desc+=[all_des.shape[0]]\n",
    "print(\"FINISHED READING THIRD SET OF IMAGES\")\n",
    "\n",
    "\n",
    "for i in range (num_train_samples):\n",
    "    image = cv2.imread(\"../../fonts-dataset/Scheherazade New/\"+str(all_image_idx[i])+\".jpeg\")\n",
    "    removed_noise = remove_noise(image)\n",
    "    kp , descriptors= sift.detectAndCompute(removed_noise,None)\n",
    "    if descriptors is not None:\n",
    "        all_des=np.vstack((all_des,descriptors))\n",
    "    print(\"processing type 4 image\"+str(i))\n",
    "\n",
    "num_of_desc+=[all_des.shape[0]]\n",
    "print(\"FINISHED READING FOURTH SET OF IMAGES\")\n",
    "\n",
    "desc_labels=np.zeros(all_des.shape[0])\n",
    "desc_labels[num_of_desc[0]:num_of_desc[1]]=1\n",
    "desc_labels[num_of_desc[1]+1:num_of_desc[2]]=2\n",
    "desc_labels[num_of_desc[2]+1:num_of_desc[3]]=3"
   ],
   "id": "17689ce1ea14eb6e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# different options for kmeans\n",
    "# - mini batches\n",
    "# - limiting the number of descriptors\n",
    "kmeans=MiniBatchKMeans(n_clusters=num_of_centroids,batch_size=num_of_centroids*1024,max_iter=20).fit(X=all_des)"
   ],
   "id": "a3543aed2af64ba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(kmeans.cluster_centers_.shape)\n",
    "print(kmeans.labels_.shape)\n",
    "print(desc_labels.shape)"
   ],
   "id": "b56edbf00134eadc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "centroids_labels=np.zeros((num_of_centroids,4))\n",
    "for i in range(num_of_centroids):\n",
    "    centroids_labels[i][0]=(np.sum(desc_labels[kmeans.labels_==i]==0))\n",
    "    centroids_labels[i][1]=(np.sum(desc_labels[kmeans.labels_==i]==1))\n",
    "    centroids_labels[i][2]=(np.sum(desc_labels[kmeans.labels_==i]==2))\n",
    "    centroids_labels[i][3]=(np.sum(desc_labels[kmeans.labels_==i]==3))\n",
    "    centroids_labels[i]/=np.sum(centroids_labels[i])"
   ],
   "id": "181cc4bad008b406",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def predict(path,centroids,centroids_labels):\n",
    "    image=cv2.imread(path)\n",
    "    removed_noise = remove_noise(image)\n",
    "    _ , descriptors= sift.detectAndCompute(removed_noise,None)\n",
    "\n",
    "    predections=[0.0,0.0,0.0,0.0]\n",
    "    if descriptors is not None:\n",
    "        for des in descriptors:\n",
    "            idx=kmeans.predict([des])\n",
    "            dist=np.linalg.norm(des-centroids[idx])\n",
    "            if dist == 0:\n",
    "                dist = 0.0000001\n",
    "            predections+=(centroids_labels[idx]/dist)\n",
    "        return np.argmax(predections)\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "K = 11\n",
    "def predict_knn(path,centroids,centroids_labels,knn):\n",
    "    image=cv2.imread(path)\n",
    "    removed_noise = remove_noise(image)\n",
    "    _ , descriptors= sift.detectAndCompute(removed_noise,None)\n",
    "\n",
    "    predections=[0.0,0.0,0.0,0.0]\n",
    "    if descriptors is not None:\n",
    "        for des in descriptors:\n",
    "            neigh=knn.kneighbors([des])\n",
    "            for i in range(K):\n",
    "                predections+=(centroids_labels[neigh[1][0][i]]/neigh[0][0][i])\n",
    "        print(predections)\n",
    "        return np.argmax(predections)\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "num_right0=0\n",
    "num_right1=0\n",
    "num_right2=0\n",
    "num_right3=0\n",
    "\n",
    "predictions=[]\n",
    "\n",
    "for i in range (num_test_samples):\n",
    "    rand_idx=str(all_image_idx[num_train_samples+i])\n",
    "    path=\"../../fonts-dataset/IBM Plex Sans Arabic/\"+rand_idx+\".jpeg\"\n",
    "\n",
    "    predicted=predict(path,kmeans.cluster_centers_,centroids_labels)\n",
    "    print(\"image\",(rand_idx), \"type0: \",predicted)\n",
    "    num_right0+=predicted==0\n",
    "    predictions.append(predicted)\n",
    "\n",
    "for i in range (num_test_samples):\n",
    "    rand_idx=str(all_image_idx[num_train_samples+i])\n",
    "    path=\"../../fonts-dataset/Lemonada/\"+rand_idx+\".jpeg\"\n",
    "\n",
    "    predicted=predict(path,kmeans.cluster_centers_,centroids_labels)\n",
    "    print(\"image\",(rand_idx), \"type1: \",predicted)\n",
    "    num_right1+=predicted==1\n",
    "    predictions.append(predicted)\n",
    "\n",
    "for i in range (num_test_samples):\n",
    "    rand_idx=str(all_image_idx[num_train_samples+i])\n",
    "\n",
    "    path=\"../../fonts-dataset/Marhey/\"+rand_idx+\".jpeg\"\n",
    "\n",
    "    predicted=predict(path,kmeans.cluster_centers_,centroids_labels)\n",
    "    print(\"image\",(rand_idx), \"type2: \",predicted)\n",
    "    num_right2+=predicted==2\n",
    "    predictions.append(predicted)\n",
    "\n",
    "for i in range (num_test_samples):\n",
    "    rand_idx=str(all_image_idx[num_train_samples+i])\n",
    "\n",
    "    path=\"../../fonts-dataset/Scheherazade New/\"+rand_idx+\".jpeg\"\n",
    "\n",
    "    predicted=predict(path,kmeans.cluster_centers_,centroids_labels)\n",
    "    print(\"image\",(rand_idx), \"type3: \",predicted)\n",
    "    num_right3+=predicted==3\n",
    "    predictions.append(predicted)"
   ],
   "id": "f39251989f1cc760",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(num_right0)\n",
    "print(num_right1)\n",
    "print(num_right2)\n",
    "print(num_right3)"
   ],
   "id": "e35f54c7110e8ae1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print((num_right0+num_right1+num_right2+num_right3)/(4*num_test_samples))",
   "id": "3c30e46ce9cf106c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "img=cv2.imread(\"../../fonts-dataset/Marhey/233.jpeg\")\n",
    "removed_noise=remove_noise(img)\n",
    "_ , descriptors= sift.detectAndCompute(removed_noise,None)\n",
    "\n",
    "predections=[0.0,0.0,0.0,0.0]\n",
    "for des in descriptors:\n",
    "    idx=kmeans.predict([des])\n",
    "    dist=np.linalg.norm(des-kmeans.cluster_centers_[idx])\n",
    "    predections+=(centroids_labels[idx]/dist)\n",
    "print(predections)\n",
    "\n",
    "show_images([removed_noise])\n"
   ],
   "id": "fbe4ce3e8873bf04",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=9)\n",
    "classes=np.arange(0, num_of_centroids, 1, dtype=int)\n",
    "knn.fit(kmeans.cluster_centers_,classes)\n",
    "_ , descriptors= sift.detectAndCompute(removed_noise,None)\n",
    "\n",
    "predections=[0.0,0.0,0.0,0.0]\n",
    "for des in descriptors:\n",
    "    idx=knn.predict([des])\n",
    "    dist=np.linalg.norm(des-kmeans.cluster_centers_[i])\n",
    "    predections+=(centroids_labels[idx]/dist)\n",
    "print(predections)"
   ],
   "id": "b3aa3fb740c6a0a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "all_des=[]\n",
    "arr = [[1,2,3],[3,4,5]]\n",
    "all_des+=arr\n",
    "all_des+=arr\n",
    "print(all_des)\n"
   ],
   "id": "3bf43f4ad053d283",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "d13de7d99386d6be",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
